\chapter{\iflanguage{english}{Theoretical Background}{Grundlagen}}
\label{cha:theoreticalBackground}

In diesem Kapitel wird eine Einführung in die Grundlagen gegeben, welche im Methoden Kapitel verwendet werden.
Zuerst wird das Mixed Reality Spektrum erläutert, anschließend das Prinzip der Head Mounted Displays. Im Abschnitt 4.3 wird AR Tracking beschrieben, welches Marker, verschiedene Arten von Markern und Tracking Algorithmen beinhaltet. Abschließend wird das bei dieser Arbeit verwendete Phantom vorgestellt.



\section{Mixed Reality}

%Bild einfügen MR Spektrum

Der Begriff \emph{Mixed Reality} (MR) wurde zuerst von Milgram und Kishino \cite{milgram_taxonomy_1994} beschrieben. Dabei handelt es sich um ein Spektrum, welches sich zwischen der realen und der virtuellen Welt aufspannt (siehe Abb. \ref{fig:4.1}). Unter der virtuellen Welt wird hierbei die \emph{Virtuelle Realität} (VR) verstanden, welche sich dadurch kennzeichnet, dass der Nutzer vollständig in eine digitalisierte Umgebung eintaucht, ohne seine reale Umwelt direkt wahrnehmen zu können. Auf dem MR Spektrum sind reale und virtuelle Welt unterschiedich stark miteinander verschmolzen. Bei der \emph{Augmented Reality} (AR) werden der realen Welt virtuelle Objekte, wie bspw. der Avatar einer sich nicht im Raum befindlichen Person, hinzugefügt \cite{bray_what_nodate}. Bei der \emph{Augmented Virtuality} (AV) werden ausgehend von der virtuellen Welt Eigenschaften des realen Raumes übernommen, wie etwa Hindernisse \cite{bray_what_nodate}. 

Heutzutage wird die MR nicht nur durch die Art des verwendeten Bildschirms beschrieben, sondern zusätzlich durch die Fähigkeit des Geräts, sich im Raum lokalisieren zu können und bspw. Geräusche räumlich korrekt widergeben zu können \cite{bray_what_nodate}. 

%Platzhalter
%TODO neue Graphik
%TODO Verweis in Text auf Abbildung

\begin{figure}[ht]
	\centering
		\includegraphics[width=0.75\textwidth]{images/IEICEfig1.png}
	\caption[Virtuality Continuum]{Mixed Reality Spektrum nach Milgram und Kishino \cite{milgram_taxonomy_1994}}
	\label{fig:4.1}
\end{figure}
 

\section{Head Mounted Displays}

Um virtuelle Objekte in der realen Welt anzeigen zu können, werden Displays benötigt. Neben Displays, welche in der Hand gehalten werden und stationär befestigten Displays, gibt es \emph{Head Mounted Displays} (HMDs). Sie werden ähnlich einer Brille auf dem Kopf getragen, das Display befindet sich vor den Augen des Nutzers. 
Im Bereich AR wird zwischen \emph{video see-through HMD} (VST-HMD) und \emph{optical see-through HMD} (OST-HMD) unterschieden.

Bei VST-HMDs wird ein Video der Umwelt aufgenommen, in welches die virtuellen Objekte mittels Methoden der Computer Vision pixelgenau eingefügt werden \cite{billinghurst_survey_2015}. Es tritt keine Zeitverzögerung zwischen Bild der realen Welt und dem darauf angezeigtem virtuellem Objekt auf. Mittels Tiefenkameras kann eine korrekte räumliche Überlagerung von virtuellen Objekten durch reale Objekte garantiert werden. Ein Nachteil von VST-HMDs ist die Tatsache, dass der Träger des HMDs die Welt nur über das Video wahrnimmt und es so zu Problemen aufgrund von begrenzter Auflösung und zeitlicher Verzögerung zwischen realer Welt und Video kommen kann \cite{billinghurst_survey_2015}.  

OST-HMDs hingegen sind Displays, welche durchsichtig sind und so den Blick auf die reale Umgebung ermöglichen. Dadurch gibt es keine Zeitverzögerung zwischen realer Welt und Szene, die der Nutzer sieht, mehr. Allerdings kann es nun zur zeitlichen Verzögerung im Rendering des virtuellen Objektes kommen. Ein weiteres großes Problem ist das Registrieren der virtuellen Objekte mit der Umwelt, da bei OST-HMDs zum positionieren dieser Objekte keine Methoden der Computer Vision verwendet werden können \cite{billinghurst_survey_2015}. Die in dieser Arbeit verwendete Microsoft Hololens lässt sich zu den OST-HMDs zählen. 




\section{Registrierung}

Im medizinischen Bereich ist es wünschenswert, verschiedene Datensätze, welche bspw. durch unterschiedliche Bildgebende Verfahren oder zu verschiedenen Zeitpunkten im Krankheitsverlauf entstanden sind, in Übereinstimmung zu bringen. So können die Datensätze gleichzeitig angezeigt werden, was die Interpretation erleichtert und das aufwändige Wechseln zwischen den verschiedenen Medien vermeidet. Dies ermöglicht eine Verbesserung von Diagnose, Planung und Therapie. Dieser Prozess des in-Übereinstimmung-bringens wird \emph{Registrierung} genannt.

In der AR bezieht sich der Begriff Registrierung auf das Problem, die Objekte der virtuellen und realen Welt miteinander in Einklang zu bringen \cite{azuma_survey_1997}. Es werden \emph{Ankerpunkte} (Anchor) benötigt, um die Hologramme am korrekten Ort anzuzeigen und dort zu halten, selbst wenn der Nutzer sich im Raum bewegt. Als Anchor können u.a. reale Objekte im Raum, bspw. Image Marker aus Papier, genutzt werden \cite{billinghurst_survey_2015}. Nach der initialen Registrierung, bei welcher die Position und Rotation (\emph{Pose}) des Nutzers in Relation zum Anchor bestimmt werden, müssen diese kontinuierlich aktualisiert werden, da der Nutzer sich im Raum bewegt \cite{billinghurst_survey_2015}. Im Folgenden werden verschiedene Tracking Methoden genannt.



\section{AR Tracking}

Generell gibt es verschiedene Tracking Methoden, wie Magnetisches Tracking, Sichtbasiertes Tracking, Inertial Tracking oder hybride Anwendungen.

Sichtbasiertes Tracking zeichnet sich dadurch aus, dass zur Berechnung der Kamerapose im Verhältnis zu Objekten im Raum Methoden aus der Computer Vision genutzt werden \cite{rabbi_survey_2013}. 
Da in dieser Arbeit sichtbasiertes Tracking verwendet wurde, wird nur dieses im Weiteren erläutert.

\subsection{Infrarot Tracking}
Beim Infrarot Tracking wird von einem Marker entweder Infrarot Strahlung ausgesendet (\emph{aktiver Marker}) oder reflektiert (\emph{passiver Marker}). Für die trackende Kamera haben diese Marker einen hohen Kontrast, da sie als helle Punkte vor dunklem Hintergrund erscheinen. Es gibt zwei Ansätze, wie Marker und Kamera konfiguriert sein können: als \emph{outside-looking-in} Konfiguration, bei welcher das zu trackende Objekt mit Markern ausgestattet und von einer stationären Kamera getrackt wird oder als \emph{inside-looking-out} Konfiguration, bei welcher das zu trackende Objekt mit einer Kamera ausgestattet wird und sich anhand von im Raum befestigten Markern orientiert \cite{billinghurst_survey_2015}.



\subsection{Visible Light Tracking}
 
%TODO Überarbeiten
Mit Hilfe von Video Aufnahmen aus RGB-Kameras, wie sie bspw. die Hololens besitzt, lassen sich Hologramme ebenso mit der realen Welt registrieren. Die dazu verwendeten Methoden lassen sich in drei Techniken aufteilen, welche im Folgenden erläutert werden. 



\textbf{Fiducial Tracking} 

\emph{Fiducials} sind phyische Objekte, die in der realen Welt platziert werden (siehe Abb.\ref{fig:4.2}). Sie können als Anchor für virtuelle Objekte genutzt werden, um diese im Raum zu positionieren. Wie ein Fiducial aussieht, ist stark von dem Algorithmus abhängig, der zum Tracken genutzt wird. So gibt es einfarbige Fiducials, die per Color Matching getrackt werden können \cite{billinghurst_survey_2015}. Hierbei muss beachtet werden, dass ein einzelner, einfarbiger Marker nicht genügend Informationen enthält, um die Kamerapose zu bestimmen. Es müssen mindestens vier Punkte im Raum erkannt werden, um diese berechnen zu können \cite{billinghurst_survey_2015}. Es muss also darauf geachtet werden, die Marker so in der realen Welt zu positionieren, dass zu jeder Zeit mindestens vier einfarbige Fiducials sichtbar sind. Dieser Mehraufwand kann vermieden werden, indem planare quadratische Marker verwendet werden, deren Ecken als die vier bekannten Punkte dienen. Zusätzlich kann ein Bild dem Marker hinzugefügt werden, um zu ermöglichen, dass mehrere Marker zeitgleich verwendet und voneinander unterschieden werden können, sowie die Rotation um die vertikale Achse feststellen zu können, wie es bspw. beim ARToolkit der Fall ist \cite{billinghurst_survey_2015}.

\begin{figure}[ht]
	\centering
		\includegraphics[width=0.75\textwidth]{images/fiducials.png}
	\caption[Fiducials]{Beispiel planare Fiducials und einfarbige Fiducials (beim zeichnen vergessen)}
	\label{fig:4.2}
\end{figure}

%genauer auf ARToolkit u.ä. eingehen?

\textbf{Natural Feature Tracking}

Natural Feature Tracking ermöglicht ein markerloses Tracking, somit müssen dem Raum keine künstlichen Merkmale in Form von Fiducials hinzugefügt werden. Algorithmen wie SIFT (Scale Invariant Feature Transform) ermitteln eindeutige Merkmale in einem Set von Referenzbildern und bilden einen Deskriptor, welcher spezifisch für dieses eine Merkmal ist und in einer Datenbank gespeichert wird. Mittels Feature Matching werden Merkmale des zu trackenden Objekts mit Merkmalen aus der Datenbank abgeglichen. Die Pose der Kamera kann nun mit den gefundenen Features ähnlich berechnet werden wie bei Fiducials \cite{billinghurst_survey_2015}.


\textbf{Modellbasiertes Tracking}

Beim modellbasiertem Tracking wird ein 3D-Modell des Objektes genutzt, welches getrackt werden soll. Auf die Szene werden Kantenfilter angewendet, welche mit mit dem 3D-Modell abgeglichen werden, wodurch die Pose der Kamera bestimmt wird. Es ist möglich, Natural Feature Tracking und die Textur des 3D-Modells mit einzubeziehen, wodurch das Tracking robuster wird \cite{billinghurst_survey_2015}.

%SLAM mit rein?

\subsection{3D Structure Tracking}

Es ist möglich, mit Hilfe von 3D-Kamerasystemen Tiefendaten zu erhalten. Diese Tiefendaten werden mittels Methoden wie time-of-flight oder strukturiertem Licht erzeugt. Bei ersterem wird die Laufzeit eines Lichtimpulses zum Objekt und zurück gemessen, sodass für jeden Pixel in der Szene eine Laufzeitmessung und somit die Distanz zur Kamera bekannt ist \cite{szeliski_computer_nodate}.
%Szeliski Buch Kapitel 12 Zitat
Bei strukturiertem Licht werden Streifen oder Punkte auf eine Oberfläche projiziert. Durch die Oberfläche wird das projizierte Muster verzerrt. Mithilfe von optischer Triangulation kann nun die 3D Position der Punkte bestimmt werden \cite{szeliski_computer_nodate}. 
Die KinectFusion nutzt strukturiertes Licht um 3D Modelle von Objekten und vom Raum zu erstellen, welche wiederum zum Tracken der Pose der Kamera genutzt werden \cite{billinghurst_survey_2015}.


\section{Phantom}

Unter einem \emph{Phantom} wird in der Medizin die Nachbildung eines Organs verstanden, an welchem Übungen und Experimente durchgeführt werden können. Das in dieser Arbeit verwendete Phantom ist das \emph{open-source Heidelberg laparoscopic phantom} (Open-HELP). Es wurde nach dem CT-Scan des Torsos eines männlichen Patienten modelliert \cite{noauthor_openhelp_nodate}. Der Torso enthält naturgetreue Organe und eine abnehmbare Bauchdecke (siehe Abb. \ref{fig:4.3}). 

\begin{figure}[ht]
	\centering
		\includegraphics[width=0.75\textwidth]{images/phantomOhneMarker.png}
	\caption[Open-HELP Phantom]{Open-HELP Phantom mit und ohne Bauchdecke}
	\label{fig:4.3}
\end{figure}
