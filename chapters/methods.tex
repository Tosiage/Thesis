\chapter{\iflanguage{english}{Methods}{Methoden}}
\label{cha:methods}

Description of your used methods, algorithms and the actual work you did. This is often the longest and most detailed chapter...

\section{Microsoft Hololens}

Das in dieser Arbeit genutzte Optical See-Through HMD ist die Hololens der ersten Generation. Die Hololens wurde 2016 von der Microsoft Corporation auf den Markt gebracht. Sie übertrifft andere kommerziell verfügbaren OST-HMDs in Kontrast und Stabilität der Bildwiederholrate und hat eine geringere Zeitverzögerung \cite{qian_comparison_2017}. Die Hololens ist nicht kabelgebunden, lässt sich über Handgesten sowie Sprachbefehle steuern und gefährdet somit nicht die Sterilität im Operationssaal \cite{pratt_through_2018}.

Ein virtuelles Objekt, welches von der Hololens angezeigt wird, wird \emph{Hologramm} genannt. Die Hololens projiziert ein Hologramm auf zwei Durchsichtdisplays (\emph{Waveguides)}, für jedes Auge eines. Im Gegensatz zu Video See-Through HMDs, welche bei einem Stromausfall dem Nutzer jegliche Sicht versperren, ermöglichen die Waveguides zeitgleich die Sicht auf die reale Umgebung. Für jeden Waveguide gibt es eine \emph{Light Engine}, welche die holographischen Inhalte projiziert. Mit Hilfe von vier Umgebungssensoren und einer Time-of-Flight Tiefenkamera kann die Hololens eine Karte des Raumes erstellen (\emph{Spatial Mapping}) und sich selbst darin Positionieren. Die Tiefenkamera wird zusätzlich zur Erkennung der Handgesten genutzt. \cite{varnauld_mixed_nodate}
%TODO richtiges Zitat Mixed Reality Documentation

\textbf{Technische Daten}

\begin{center}
\begin{tabular}{ll}
\hline
\textbf{Komponente}    & \textbf{Daten}   \\
\hline
\textbf{Optik}      & 2 Durchsichtdisplays (Waveguides)\\
          & 2 HD 16:9 Light Engines \\
          &\\
\textbf{Holographische Auflösung} & 2,3 Millionen Lichtpunkte\\
  &\\
\textbf{Holographische Dichte} & mehr als 2500 Radianten \\
&(2500 Lichtpunkte pro Radiant, \\
& wobei $1 rad \approx 57,3^\circ $ ) \\
  &\\
\textbf{Sensoren}       & 1 IMU (Inertiale Messeinheit)       \\
& 4 Umgebungssensoren \\
& 1 Tiefenkamera (Time-of-Flight) \\
&1 2MP HD Kamera \\
&4 Mikrofone\\
&1 Umgebungslichtsensor\\
  &\\
\textbf{Interaktion}       & räumlicher Ton           \\
& Blickverfolgung\\
& Handgesten \\
& Sprachsteuerung (bei Internetverbingung)\\
  &\\
\textbf{Leistung} & 2-3 Stunden aktive Nutzung            \\
  &bis zu 2 Wochen standby\\
  &nutzbar während des Ladevorgangs\\
  &passive Kühlung\\
  &\\
\textbf{Prozessoren} &    Intel 32 bit architecture \\
& Microsoft Holographic Processing Unit (HPU 1.0)         \\
  &\\
\textbf{Betriebssystem} & Windows 10           \\
\hline
\end{tabular}
\end{center}



\section{NDI Polaris Spectra}

Die Polaris Spectra von Northern Digital Inc. ist ein Infrarot Tracking System zur Anwendung im medizinischen Bereich. Die Polaris ist als outside-looking-in System konfiguriert und somit nicht sehr mobil. Die zu trackenden Objekte werden mit Markern ausgestattet und von einem stationären Infrarotsensor getrackt. Die Polaris kann sowohl aktive als auch passive Marker tracken. Aktive Marker werden durch ein elektrisches Signal aktiviert und senden Infrarotstrahlung aus. Passive Marker besitzen mindestens vier reflektive Kugeln. Der Infrarotsensor der Polaris sendet Infrarotstrahlung aus, welche von den passiven Markern reflektiert wird. Anhand der erhaltenen Informationen kann der Infrarotsensor die Position und Rotation der Marker bestimmen. 

\textbf{Technische Daten}

%https://www.ndigital.com/medical/products/polaris-family/

\begin{center}
\begin{tabular}{ll}
\hline
\textbf{Komponente}    & \textbf{Daten}   \\
\hline
\textbf{Marker}      & passiv, aktiv, kabellos aktiv\\
          &\\
\textbf{Max. Anzahl passiver Marker} & 32 passive Marker\\
  &\\
\textbf{Max. Update Rate} & 60Hz \\
&\\
\textbf{Infrarotsensor Maße} & 613 mm x 104 mm x 86 mm\\
&\\
\textbf{Infrarotsensor Anbringung} &  Anbringung erhöht an Wand oder Stativ\\
&Fixierung an Rückseite\\
&\\
\textbf{Max. Messvolumen} & Beginn Messung in 950 mm Entfernung von Infrarotsensor\\ & 1856 mm x 1470 mm x 2050 mm (Breite x Höhe x Tiefe)\\
\hline
\end{tabular}
\end{center}

\section{Unity}

\emph{Unity} ist eine Gaming Engine entwickelt von Unity Technologies. Sie kann zum Entwickeln von 3D- und 2D-Spielen genutzt werden, sowie unter anderem zum Erstellen von AR- und VR-Anwendungen. Unity unterstützt mehr als 25 Plattformen, darunter auch die Universal Windows Plattform, welche auf der Hololens genutzt wird. Microsoft empfiehlt Unity zum Entwickeln von MR-Anwendungen für die Hololens, mit der Begründung, dass Unity 'die schnellste Methode zum Erstellen einer Mixed Reality-App' sei \cite{varnauld_mixed_nodate}.
%Wie die MR Docs zitieren?
In dieser Arbeit wurde Unity 2018.2.21f1 genutzt.

\section{Mixed Reality Toolkit}

Das \emph{Mixed Reality Toolkit} (MRTK) für Unity ist ein von Microsoft geleitetes Open Source Projekt zur Unterstützung und Beschleunigung der Entwicklung für die Hololens, Windows Mixed Reality immersive (VR) Headsets und OpenVR. Es enthält verschiedene Bauteile in Form von Skripten und vorgefertigten Objekten (Assets). 
Eines dieser Assets ist das \emph{Input Manager Prefab}, das sich unter anderem aus einem \emph{Gaze Manager}, einem \emph{Input Manager} und einem \emph{Focus Manager} Skript zusammensetzt. Mit Hilfe dieser Skripte lässt sich der Blick des Nutzers verfolgen und Gesten erkennen. Die Verfolgung der Blickrichtung ermöglicht das Anzeigen eines Cursors für den Nutzer und dadurch das Anfokussieren einzelner Objekte in der Szene. So besteht die Möglichkeit, Objekte bei Fokussierung farblich hervorzuheben oder weitere Informationen anzuzeigen, die sonst nicht sichtbar sind. 
In dieser Arbeit wurde die MRTK Version 2017.4.3.0 verwendet.
%https://microsoft.github.io/MixedRealityToolkit-Unity/README.html

\section{Vuforia Augmented Reality SDK}

Vuforia ist ein plattformübergreifendes Software Development Kit zur Entwicklung von Mixed Reality Anwendungen. Vuforia lässt sich sowohl mit iOS- und Android-Geräten als auch mit der Hololens nutzen. Es ist in Unity integriert und ermöglicht durch Methoden der Computer Vision das Tracken von Markern in verschiedenen Formen, wie z.B. das Tracken eines einzelnen Bildes, 3D-Konfigurationen mit mehreren Bildern oder eines 3D Objektes. Vuforia ist nicht open source. Die in dieser Arbeit genutzte Version der Vuforia Engine ist 8.0.10.

Vuforia stellt in der Unity Szene ein eigenes Kamera-Asset zur Verfügung, welches in dieser Arbeit Anstelle des MixedRealityCameraParent-Assets aus dem Mixed Reality Toolkit verwendet wird.

\subsection{Vuforia Model Targets}

%https://library.vuforia.com/features/objects/model-targets.html
\emph{Vuforia Model Targets} ermöglichen es, Objekte aus der realen Welt basierend auf ihrer Form zu Tracken. Dabei kann es sich um ein kleines Objekt wie ein Spielzeugauto handeln, aber auch um ein großes Objekt, wie ein richtiges Auto. Eine Voraussetzung hierfür ist jedoch, dass ein 3D-Modell (bspw. ein CAD-Modell) des Objektes existiert. Damit das Tracking eines Model Targets gut funktioniert, müssen sowohl das Objekt, als auch das CAD-Modell einige Anforderungen erfüllen.   

Ein Objekt, das getrackt werden soll, sollte:
\begin{itemize}
%Fixed Position in Space
\item Fix im Raum angebracht sein

%Colored or Patterned surface
\item Eine farbige oder gemusterte Oberfläche besitzen

%Sufficient Geometric Detail
\item Komplex sein

%non-flexible and rigid
\item Keine beweglichen Teile haben und nicht verformbar sein
\end{itemize}
%TODO genauer?


Das CAD-Modell sollte:
\begin{itemize}
\item Keine Löcher oder Risse aufweisen
\item Keine fehlenden Teile haben
\item Keine Normalen aufweisen, die in eine andere Richtung als die Oberflächennormale zeigen
\item Keine fehlenden Farbinformationen oder fehlende Textur aufweisen
\item Keine falsche Textur aufweisen
\end{itemize}


\textbf{Vuforia Model Target Generator}

Um ein Model Target für die Verwendung in Unity zu erstellen, hat Vuforia den \emph{Model Target Generator} (MTG) entwickelt. Mit Hilfe des MTGs wird aus einem CAD-Modell eine Vuforia Datenbank generiert, welche als \emph{.unitypackage} heruntergeladen und in Unity importiert werden kann. 

\textbf{Guide Views}



\subsection{Vuforia Image Targets}
Was sind Image Targets?

Wie sieht ein gutes image target aus?

Die image targets die ich genutzt habe? Oder erst später?

\section{Versuchsaufbau}
Modell Target Phantom
Box
Phantom

\section{Kalibrierung}
mit Hololens
mit Polaris

\section{GUI und Interaktion}
man muss mit dem Hologramm interagieren wegen kalibrierung
zwei möglichkeiten für GUI 
1. box transparent
2. rendering reihenfolge (box muss von achsen überlagert werden)

für 2. entschieden, da bei box transparent buttons drin liegen und so nicht ersichtlich dass interagiert werden kann


